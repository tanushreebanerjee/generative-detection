[rank: 0] Global seed set to 23
[rank: 2] Global seed set to 23
[rank: 3] Global seed set to 23
[rank: 1] Global seed set to 23
INFO:root:Options: {
  "transformers_cache": ".cache/transformers_cache",
  "torch_home": ".cache/torch_home",
  "logging_level": "INFO",
  "name": "od_vae_test_1gpu",
  "resume": "",
  "base": [
    "configs/autoencoder/pose/jo_autoencoder_kl_16x16x16.yaml"
  ],
  "train": true,
  "no_test": false,
  "project": null,
  "debug": false,
  "seed": 23,
  "postfix": "",
  "logdir": "logs",
  "scale_lr": true,
  "logger": true,
  "enable_checkpointing": true,
  "default_root_dir": null,
  "gradient_clip_val": null,
  "gradient_clip_algorithm": null,
  "num_nodes": 1,
  "num_processes": null,
  "devices": "4",
  "gpus": null,
  "auto_select_gpus": null,
  "tpu_cores": null,
  "ipus": null,
  "enable_progress_bar": true,
  "overfit_batches": 0.0,
  "track_grad_norm": -1,
  "check_val_every_n_epoch": 1,
  "fast_dev_run": false,
  "accumulate_grad_batches": null,
  "max_epochs": null,
  "min_epochs": null,
  "max_steps": -1,
  "min_steps": null,
  "max_time": null,
  "limit_train_batches": null,
  "limit_val_batches": null,
  "limit_test_batches": null,
  "limit_predict_batches": null,
  "val_check_interval": null,
  "log_every_n_steps": 50,
  "accelerator": null,
  "strategy": null,
  "sync_batchnorm": false,
  "precision": 32,
  "enable_model_summary": true,
  "num_sanity_val_steps": 2,
  "resume_from_checkpoint": null,
  "profiler": null,
  "benchmark": null,
  "reload_dataloaders_every_n_epochs": 0,
  "auto_lr_find": false,
  "replace_sampler_ddp": true,
  "detect_anomaly": false,
  "auto_scale_batch_size": false,
  "plugins": null,
  "amp_backend": null,
  "amp_level": null,
  "move_metrics_to_cpu": false,
  "multiple_trainloader_mode": "max_size_cycle",
  "inference_mode": true
}
INFO:root:Options: {
  "transformers_cache": ".cache/transformers_cache",
  "torch_home": ".cache/torch_home",
  "logging_level": "INFO",
  "name": "od_vae_test_1gpu",
  "resume": "",
  "base": [
    "configs/autoencoder/pose/jo_autoencoder_kl_16x16x16.yaml"
  ],
  "train": true,
  "no_test": false,
  "project": null,
  "debug": false,
  "seed": 23,
  "postfix": "",
  "logdir": "logs",
  "scale_lr": true,
  "logger": true,
  "enable_checkpointing": true,
  "default_root_dir": null,
  "gradient_clip_val": null,
  "gradient_clip_algorithm": null,
  "num_nodes": 1,
  "num_processes": null,
  "devices": "4",
  "gpus": null,
  "auto_select_gpus": null,
  "tpu_cores": null,
  "ipus": null,
  "enable_progress_bar": true,
  "overfit_batches": 0.0,
  "track_grad_norm": -1,
  "check_val_every_n_epoch": 1,
  "fast_dev_run": false,
  "accumulate_grad_batches": null,
  "max_epochs": null,
  "min_epochs": null,
  "max_steps": -1,
  "min_steps": null,
  "max_time": null,
  "limit_train_batches": null,
  "limit_val_batches": null,
  "limit_test_batches": null,
  "limit_predict_batches": null,
  "val_check_interval": null,
  "log_every_n_steps": 50,
  "accelerator": null,
  "strategy": null,
  "sync_batchnorm": false,
  "precision": 32,
  "enable_model_summary": true,
  "num_sanity_val_steps": 2,
  "resume_from_checkpoint": null,
  "profiler": null,
  "benchmark": null,
  "reload_dataloaders_every_n_epochs": 0,
  "auto_lr_find": false,
  "replace_sampler_ddp": true,
  "detect_anomaly": false,
  "auto_scale_batch_size": false,
  "plugins": null,
  "amp_backend": null,
  "amp_level": null,
  "move_metrics_to_cpu": false,
  "multiple_trainloader_mode": "max_size_cycle",
  "inference_mode": true
}
INFO:root:Options: {
  "transformers_cache": ".cache/transformers_cache",
  "torch_home": ".cache/torch_home",
  "logging_level": "INFO",
  "name": "od_vae_test_1gpu",
  "resume": "",
  "base": [
    "configs/autoencoder/pose/jo_autoencoder_kl_16x16x16.yaml"
  ],
  "train": true,
  "no_test": false,
  "project": null,
  "debug": false,
  "seed": 23,
  "postfix": "",
  "logdir": "logs",
  "scale_lr": true,
  "logger": true,
  "enable_checkpointing": true,
  "default_root_dir": null,
  "gradient_clip_val": null,
  "gradient_clip_algorithm": null,
  "num_nodes": 1,
  "num_processes": null,
  "devices": "4",
  "gpus": null,
  "auto_select_gpus": null,
  "tpu_cores": null,
  "ipus": null,
  "enable_progress_bar": true,
  "overfit_batches": 0.0,
  "track_grad_norm": -1,
  "check_val_every_n_epoch": 1,
  "fast_dev_run": false,
  "accumulate_grad_batches": null,
  "max_epochs": null,
  "min_epochs": null,
  "max_steps": -1,
  "min_steps": null,
  "max_time": null,
  "limit_train_batches": null,
  "limit_val_batches": null,
  "limit_test_batches": null,
  "limit_predict_batches": null,
  "val_check_interval": null,
  "log_every_n_steps": 50,
  "accelerator": null,
  "strategy": null,
  "sync_batchnorm": false,
  "precision": 32,
  "enable_model_summary": true,
  "num_sanity_val_steps": 2,
  "resume_from_checkpoint": null,
  "profiler": null,
  "benchmark": null,
  "reload_dataloaders_every_n_epochs": 0,
  "auto_lr_find": false,
  "replace_sampler_ddp": true,
  "detect_anomaly": false,
  "auto_scale_batch_size": false,
  "plugins": null,
  "amp_backend": null,
  "amp_level": null,
  "move_metrics_to_cpu": false,
  "multiple_trainloader_mode": "max_size_cycle",
  "inference_mode": true
}
INFO:root:Options: {
  "transformers_cache": ".cache/transformers_cache",
  "torch_home": ".cache/torch_home",
  "logging_level": "INFO",
  "name": "od_vae_test_1gpu",
  "resume": "",
  "base": [
    "configs/autoencoder/pose/jo_autoencoder_kl_16x16x16.yaml"
  ],
  "train": true,
  "no_test": false,
  "project": null,
  "debug": false,
  "seed": 23,
  "postfix": "",
  "logdir": "logs",
  "scale_lr": true,
  "logger": true,
  "enable_checkpointing": true,
  "default_root_dir": null,
  "gradient_clip_val": null,
  "gradient_clip_algorithm": null,
  "num_nodes": 1,
  "num_processes": null,
  "devices": "4",
  "gpus": null,
  "auto_select_gpus": null,
  "tpu_cores": null,
  "ipus": null,
  "enable_progress_bar": true,
  "overfit_batches": 0.0,
  "track_grad_norm": -1,
  "check_val_every_n_epoch": 1,
  "fast_dev_run": false,
  "accumulate_grad_batches": null,
  "max_epochs": null,
  "min_epochs": null,
  "max_steps": -1,
  "min_steps": null,
  "max_time": null,
  "limit_train_batches": null,
  "limit_val_batches": null,
  "limit_test_batches": null,
  "limit_predict_batches": null,
  "val_check_interval": null,
  "log_every_n_steps": 50,
  "accelerator": null,
  "strategy": null,
  "sync_batchnorm": false,
  "precision": 32,
  "enable_model_summary": true,
  "num_sanity_val_steps": 2,
  "resume_from_checkpoint": null,
  "profiler": null,
  "benchmark": null,
  "reload_dataloaders_every_n_epochs": 0,
  "auto_lr_find": false,
  "replace_sampler_ddp": true,
  "detect_anomaly": false,
  "auto_scale_batch_size": false,
  "plugins": null,
  "amp_backend": null,
  "amp_level": null,
  "move_metrics_to_cpu": false,
  "multiple_trainloader_mode": "max_size_cycle",
  "inference_mode": true
}
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/modules/losses/contperceptual.py:104: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  parameters = torch.tensor(parameters)
/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/modules/losses/contperceptual.py:104: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  parameters = torch.tensor(parameters)
/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/modules/losses/contperceptual.py:104: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  parameters = torch.tensor(parameters)
/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/modules/losses/contperceptual.py:104: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  parameters = torch.tensor(parameters)
INFO:root:Monitoring val/rec_loss as checkpoint metric.
INFO:root:Using ModelCheckpoint with {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': 'logs/2024-05-17T17-05-32_od_vae_test_1gpu/checkpoints', 'filename': '{epoch:06}', 'verbose': True, 'save_last': True, 'monitor': 'val/rec_loss', 'save_top_k': 3}}
INFO:root:Merged modelckpt-cfg: 
{'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': 'logs/2024-05-17T17-05-32_od_vae_test_1gpu/checkpoints', 'filename': '{epoch:06}', 'verbose': True, 'save_last': True, 'monitor': 'val/rec_loss', 'save_top_k': 3}}
INFO:root:Monitoring val/rec_loss as checkpoint metric.
INFO:root:Using ModelCheckpoint with {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': 'logs/2024-05-17T17-05-32_od_vae_test_1gpu/checkpoints', 'filename': '{epoch:06}', 'verbose': True, 'save_last': True, 'monitor': 'val/rec_loss', 'save_top_k': 3}}
INFO:root:Merged modelckpt-cfg: 
{'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': 'logs/2024-05-17T17-05-32_od_vae_test_1gpu/checkpoints', 'filename': '{epoch:06}', 'verbose': True, 'save_last': True, 'monitor': 'val/rec_loss', 'save_top_k': 3}}
INFO:root:Monitoring val/rec_loss as checkpoint metric.
INFO:root:Using ModelCheckpoint with {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': 'logs/2024-05-17T17-05-32_od_vae_test_1gpu/checkpoints', 'filename': '{epoch:06}', 'verbose': True, 'save_last': True, 'monitor': 'val/rec_loss', 'save_top_k': 3}}
INFO:root:Merged modelckpt-cfg: 
{'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': 'logs/2024-05-17T17-05-32_od_vae_test_1gpu/checkpoints', 'filename': '{epoch:06}', 'verbose': True, 'save_last': True, 'monitor': 'val/rec_loss', 'save_top_k': 3}}
wandb: Currently logged in as: ostjul (ostjul13). Use `wandb login --relogin` to force relogin
wandb: WARNING Path logs/2024-05-17T17-05-32_od_vae_test_1gpu/wandb/ wasn't writable, using system temp directory.
wandb: WARNING Path logs/2024-05-17T17-05-32_od_vae_test_1gpu/wandb/ wasn't writable, using system temp directory
making attention of type 'vanilla' with 256 in_channels
making attention of type 'vanilla' with 256 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 16, 4, 4) = 256 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 256 in_channels
making attention of type 'vanilla' with 256 in_channels
making attention of type 'vanilla' with 256 in_channels
loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth
Loaded dataset stats:
{'t1': tensor([ 7.6356e-09, -1.8421e+01]), 't2': tensor([ 2.9980e-09, -1.8421e+01]), 't3': tensor([ 0.2343, -2.6865]), 'v3': tensor([0.1066, 1.1088]), 'l': tensor([ 2.6797, -2.4134]), 'h': tensor([ 1.7426, -2.7465]), 'w': tensor([ 1.1360, -4.0951]), 'yaw': tensor([0.1067, 1.1239]), 'fill_factor': tensor([ 0.4094, -3.2034])}
05/17 17:05:39 - mmengine - INFO - ------------------------------
05/17 17:05:39 - mmengine - INFO - The length of training dataset: 1938
05/17 17:05:39 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 5051   |
| truck                | 525    |
| trailer              | 60     |
| bus                  | 369    |
| construction_vehicle | 196    |
| bicycle              | 191    |
| motorcycle           | 212    |
| pedestrian           | 3657   |
| traffic_cone         | 1339   |
| barrier              | 2323   |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
making attention of type 'vanilla' with 256 in_channels
making attention of type 'vanilla' with 256 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 16, 4, 4) = 256 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 256 in_channels
making attention of type 'vanilla' with 256 in_channels
making attention of type 'vanilla' with 256 in_channels
loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth
Loaded dataset stats:
{'t1': tensor([ 7.6356e-09, -1.8421e+01]), 't2': tensor([ 2.9980e-09, -1.8421e+01]), 't3': tensor([ 0.2343, -2.6865]), 'v3': tensor([0.1066, 1.1088]), 'l': tensor([ 2.6797, -2.4134]), 'h': tensor([ 1.7426, -2.7465]), 'w': tensor([ 1.1360, -4.0951]), 'yaw': tensor([0.1067, 1.1239]), 'fill_factor': tensor([ 0.4094, -3.2034])}
05/17 17:05:39 - mmengine - INFO - ------------------------------
05/17 17:05:39 - mmengine - INFO - The length of training dataset: 1938
05/17 17:05:39 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 5051   |
| truck                | 525    |
| trailer              | 60     |
| bus                  | 369    |
| construction_vehicle | 196    |
| bicycle              | 191    |
| motorcycle           | 212    |
| pedestrian           | 3657   |
| traffic_cone         | 1339   |
| barrier              | 2323   |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
making attention of type 'vanilla' with 256 in_channels
making attention of type 'vanilla' with 256 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 16, 4, 4) = 256 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 256 in_channels
making attention of type 'vanilla' with 256 in_channels
making attention of type 'vanilla' with 256 in_channels
loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth
Loaded dataset stats:
{'t1': tensor([ 7.6356e-09, -1.8421e+01]), 't2': tensor([ 2.9980e-09, -1.8421e+01]), 't3': tensor([ 0.2343, -2.6865]), 'v3': tensor([0.1066, 1.1088]), 'l': tensor([ 2.6797, -2.4134]), 'h': tensor([ 1.7426, -2.7465]), 'w': tensor([ 1.1360, -4.0951]), 'yaw': tensor([0.1067, 1.1239]), 'fill_factor': tensor([ 0.4094, -3.2034])}
05/17 17:05:39 - mmengine - INFO - ------------------------------
05/17 17:05:39 - mmengine - INFO - The length of training dataset: 1938
05/17 17:05:39 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 5051   |
| truck                | 525    |
| trailer              | 60     |
| bus                  | 369    |
| construction_vehicle | 196    |
| bicycle              | 191    |
| motorcycle           | 212    |
| pedestrian           | 3657   |
| traffic_cone         | 1339   |
| barrier              | 2323   |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
05/17 17:05:39 - mmengine - INFO - ------------------------------
05/17 17:05:39 - mmengine - INFO - The length of training dataset: 486
05/17 17:05:39 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 2568   |
| truck                | 124    |
| trailer              | 0      |
| bus                  | 41     |
| construction_vehicle | 0      |
| bicycle              | 52     |
| motorcycle           | 259    |
| pedestrian           | 1358   |
| traffic_cone         | 39     |
| barrier              | 0      |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
05/17 17:05:39 - mmengine - INFO - ------------------------------
05/17 17:05:39 - mmengine - INFO - The length of training dataset: 486
05/17 17:05:39 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 2568   |
| truck                | 124    |
| trailer              | 0      |
| bus                  | 41     |
| construction_vehicle | 0      |
| bicycle              | 52     |
| motorcycle           | 259    |
| pedestrian           | 1358   |
| traffic_cone         | 39     |
| barrier              | 0      |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
05/17 17:05:39 - mmengine - INFO - ------------------------------
05/17 17:05:39 - mmengine - INFO - The length of training dataset: 486
05/17 17:05:39 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 2568   |
| truck                | 124    |
| trailer              | 0      |
| bus                  | 41     |
| construction_vehicle | 0      |
| bicycle              | 52     |
| motorcycle           | 259    |
| pedestrian           | 1358   |
| traffic_cone         | 39     |
| barrier              | 0      |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
05/17 17:05:40 - mmengine - INFO - ------------------------------
05/17 17:05:40 - mmengine - INFO - The length of training dataset: 1938
05/17 17:05:40 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 5051   |
| truck                | 525    |
| trailer              | 60     |
| bus                  | 369    |
| construction_vehicle | 196    |
| bicycle              | 191    |
| motorcycle           | 212    |
| pedestrian           | 3657   |
| traffic_cone         | 1339   |
| barrier              | 2323   |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
05/17 17:05:40 - mmengine - INFO - ------------------------------
05/17 17:05:40 - mmengine - INFO - The length of training dataset: 1938
05/17 17:05:40 - mmengine - INFO - ------------------------------
05/17 17:05:40 - mmengine - INFO - The length of training dataset: 1938
05/17 17:05:40 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 5051   |
| truck                | 525    |
| trailer              | 60     |
| bus                  | 369    |
| construction_vehicle | 196    |
| bicycle              | 191    |
| motorcycle           | 212    |
| pedestrian           | 3657   |
| traffic_cone         | 1339   |
| barrier              | 2323   |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
05/17 17:05:40 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 5051   |
| truck                | 525    |
| trailer              | 60     |
| bus                  | 369    |
| construction_vehicle | 196    |
| bicycle              | 191    |
| motorcycle           | 212    |
| pedestrian           | 3657   |
| traffic_cone         | 1339   |
| barrier              | 2323   |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
05/17 17:05:40 - mmengine - INFO - ------------------------------
05/17 17:05:40 - mmengine - INFO - The length of training dataset: 486
05/17 17:05:40 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 2568   |
| truck                | 124    |
| trailer              | 0      |
| bus                  | 41     |
| construction_vehicle | 0      |
| bicycle              | 52     |
| motorcycle           | 259    |
| pedestrian           | 1358   |
| traffic_cone         | 39     |
| barrier              | 0      |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
INFO:root:#### Data #####
INFO:root:train, WrappedDataset, 1938
INFO:root:validation, WrappedDataset, 486
INFO:root:accumulate_grad_batches = 1
INFO:root:Setting learning rate to 1.80e-05 = 1 (accumulate_grad_batches) * 1 (num_gpus) * 4 (batchsize) * 4.50e-06 (base_lr)
05/17 17:05:40 - mmengine - INFO - ------------------------------
05/17 17:05:40 - mmengine - INFO - The length of training dataset: 486
05/17 17:05:40 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 2568   |
| truck                | 124    |
| trailer              | 0      |
| bus                  | 41     |
| construction_vehicle | 0      |
| bicycle              | 52     |
| motorcycle           | 259    |
| pedestrian           | 1358   |
| traffic_cone         | 39     |
| barrier              | 0      |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
INFO:root:#### Data #####
INFO:root:train, WrappedDataset, 1938
INFO:root:validation, WrappedDataset, 486
INFO:root:accumulate_grad_batches = 1
INFO:root:Setting learning rate to 1.80e-05 = 1 (accumulate_grad_batches) * 1 (num_gpus) * 4 (batchsize) * 4.50e-06 (base_lr)
[rank: 1] Global seed set to 23
[rank: 3] Global seed set to 23
05/17 17:05:40 - mmengine - INFO - ------------------------------
05/17 17:05:40 - mmengine - INFO - The length of training dataset: 486
05/17 17:05:40 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 2568   |
| truck                | 124    |
| trailer              | 0      |
| bus                  | 41     |
| construction_vehicle | 0      |
| bicycle              | 52     |
| motorcycle           | 259    |
| pedestrian           | 1358   |
| traffic_cone         | 39     |
| barrier              | 0      |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
INFO:root:#### Data #####
INFO:root:train, WrappedDataset, 1938
INFO:root:validation, WrappedDataset, 486
INFO:root:accumulate_grad_batches = 1
INFO:root:Setting learning rate to 1.80e-05 = 1 (accumulate_grad_batches) * 1 (num_gpus) * 4 (batchsize) * 4.50e-06 (base_lr)
[rank: 2] Global seed set to 23
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4
Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4
Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /tmp/wandb/run-20240517_170538-2024-05-17T17-05-32_od_vae_test_1gpu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 2024-05-17T17-05-32_od_vae_test_1gpu
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ostjul13/lightning_logs
wandb: üöÄ View run at https://wandb.ai/ostjul13/lightning_logs/runs/2024-05-17T17-05-32_od_vae_test_1gpu
INFO:root:Monitoring val/rec_loss as checkpoint metric.
INFO:root:Using ModelCheckpoint with {'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': 'logs/2024-05-17T17-05-32_od_vae_test_1gpu/checkpoints', 'filename': '{epoch:06}', 'verbose': True, 'save_last': True, 'monitor': 'val/rec_loss', 'save_top_k': 3}}
INFO:root:Merged modelckpt-cfg: 
{'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': 'logs/2024-05-17T17-05-32_od_vae_test_1gpu/checkpoints', 'filename': '{epoch:06}', 'verbose': True, 'save_last': True, 'monitor': 'val/rec_loss', 'save_top_k': 3}}
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
making attention of type 'vanilla' with 256 in_channels
making attention of type 'vanilla' with 256 in_channels
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 16, 4, 4) = 256 dimensions.
making attention of type 'vanilla' with 512 in_channels
making attention of type 'vanilla' with 256 in_channels
making attention of type 'vanilla' with 256 in_channels
making attention of type 'vanilla' with 256 in_channels
loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth
Loaded dataset stats:
{'t1': tensor([ 7.6356e-09, -1.8421e+01]), 't2': tensor([ 2.9980e-09, -1.8421e+01]), 't3': tensor([ 0.2343, -2.6865]), 'v3': tensor([0.1066, 1.1088]), 'l': tensor([ 2.6797, -2.4134]), 'h': tensor([ 1.7426, -2.7465]), 'w': tensor([ 1.1360, -4.0951]), 'yaw': tensor([0.1067, 1.1239]), 'fill_factor': tensor([ 0.4094, -3.2034])}
05/17 17:05:45 - mmengine - INFO - ------------------------------
05/17 17:05:45 - mmengine - INFO - The length of training dataset: 1938
05/17 17:05:45 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 5051   |
| truck                | 525    |
| trailer              | 60     |
| bus                  | 369    |
| construction_vehicle | 196    |
| bicycle              | 191    |
| motorcycle           | 212    |
| pedestrian           | 3657   |
| traffic_cone         | 1339   |
| barrier              | 2323   |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
05/17 17:05:46 - mmengine - INFO - ------------------------------
05/17 17:05:46 - mmengine - INFO - The length of training dataset: 486
05/17 17:05:46 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 2568   |
| truck                | 124    |
| trailer              | 0      |
| bus                  | 41     |
| construction_vehicle | 0      |
| bicycle              | 52     |
| motorcycle           | 259    |
| pedestrian           | 1358   |
| traffic_cone         | 39     |
| barrier              | 0      |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
05/17 17:05:47 - mmengine - INFO - ------------------------------
05/17 17:05:47 - mmengine - INFO - The length of training dataset: 1938
05/17 17:05:47 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 5051   |
| truck                | 525    |
| trailer              | 60     |
| bus                  | 369    |
| construction_vehicle | 196    |
| bicycle              | 191    |
| motorcycle           | 212    |
| pedestrian           | 3657   |
| traffic_cone         | 1339   |
| barrier              | 2323   |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
05/17 17:05:47 - mmengine - INFO - ------------------------------
05/17 17:05:47 - mmengine - INFO - The length of training dataset: 486
05/17 17:05:47 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 2568   |
| truck                | 124    |
| trailer              | 0      |
| bus                  | 41     |
| construction_vehicle | 0      |
| bicycle              | 52     |
| motorcycle           | 259    |
| pedestrian           | 1358   |
| traffic_cone         | 39     |
| barrier              | 0      |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
INFO:root:#### Data #####
INFO:root:train, WrappedDataset, 1938
INFO:root:validation, WrappedDataset, 486
INFO:root:accumulate_grad_batches = 1
INFO:root:Setting learning rate to 1.80e-05 = 1 (accumulate_grad_batches) * 1 (num_gpus) * 4 (batchsize) * 4.50e-06 (base_lr)
05/17 17:05:48 - mmengine - INFO - ------------------------------
05/17 17:05:48 - mmengine - INFO - The length of training dataset: 1938
05/17 17:05:48 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 5051   |
| truck                | 525    |
| trailer              | 60     |
| bus                  | 369    |
| construction_vehicle | 196    |
| bicycle              | 191    |
| motorcycle           | 212    |
| pedestrian           | 3657   |
| traffic_cone         | 1339   |
| barrier              | 2323   |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
05/17 17:05:48 - mmengine - INFO - ------------------------------
05/17 17:05:48 - mmengine - INFO - The length of training dataset: 486
05/17 17:05:48 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 2568   |
| truck                | 124    |
| trailer              | 0      |
| bus                  | 41     |
| construction_vehicle | 0      |
| bicycle              | 52     |
| motorcycle           | 259    |
| pedestrian           | 1358   |
| traffic_cone         | 39     |
| barrier              | 0      |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
[rank: 0] Global seed set to 23
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4
INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 3
INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 1
INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 2
INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 0
INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

You are using a CUDA device ('NVIDIA RTX A6000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
node209:729898:729898 [0] NCCL INFO Bootstrap : Using ens6f0np0:172.17.26.129<0>
node209:729898:729898 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node209:729898:729898 [0] NCCL INFO NET/IB : No device found.
node209:729898:729898 [0] NCCL INFO NET/Socket : Using [0]ens6f0np0:172.17.26.129<0>
node209:729898:729898 [0] NCCL INFO Using network Socket
INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
You are using a CUDA device ('NVIDIA RTX A6000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
NCCL version 2.10.3+cuda11.6
INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
You are using a CUDA device ('NVIDIA RTX A6000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
You are using a CUDA device ('NVIDIA RTX A6000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
node209:729899:729899 [1] NCCL INFO Bootstrap : Using ens6f0np0:172.17.26.129<0>
node209:729899:729899 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node209:729899:729899 [1] NCCL INFO NET/IB : No device found.
node209:729899:729899 [1] NCCL INFO NET/Socket : Using [0]ens6f0np0:172.17.26.129<0>
node209:729899:729899 [1] NCCL INFO Using network Socket
node209:729901:729901 [3] NCCL INFO Bootstrap : Using ens6f0np0:172.17.26.129<0>
node209:729901:729901 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node209:729901:729901 [3] NCCL INFO NET/IB : No device found.
node209:729901:729901 [3] NCCL INFO NET/Socket : Using [0]ens6f0np0:172.17.26.129<0>
node209:729901:729901 [3] NCCL INFO Using network Socket
node209:729900:729900 [2] NCCL INFO Bootstrap : Using ens6f0np0:172.17.26.129<0>
node209:729900:729900 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node209:729900:729900 [2] NCCL INFO NET/IB : No device found.
node209:729900:729900 [2] NCCL INFO NET/Socket : Using [0]ens6f0np0:172.17.26.129<0>
node209:729900:729900 [2] NCCL INFO Using network Socket
node209:729898:730330 [0] NCCL INFO Channel 00/02 :    0   1   2   3
node209:729898:730330 [0] NCCL INFO Channel 01/02 :    0   1   2   3
node209:729898:730330 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
node209:729899:730334 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0
node209:729899:730334 [1] NCCL INFO Setting affinity for GPU 1 to ff,fff00000,000fffff
node209:729900:730336 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1
node209:729900:730336 [2] NCCL INFO Setting affinity for GPU 2 to ff,fff00000,000fffff
node209:729901:730335 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2
node209:729901:730335 [3] NCCL INFO Setting affinity for GPU 3 to ff,fff00000,000fffff
node209:729898:730330 [0] NCCL INFO Setting affinity for GPU 0 to ff,fff00000,000fffff
node209:729898:730330 [0] NCCL INFO Channel 00 : 0[5b000] -> 1[5e000] via P2P/IPC
node209:729900:730336 [2] NCCL INFO Channel 00 : 2[5f000] -> 3[62000] via P2P/IPC
node209:729901:730335 [3] NCCL INFO Channel 00 : 3[62000] -> 0[5b000] via P2P/IPC
node209:729898:730330 [0] NCCL INFO Channel 01 : 0[5b000] -> 1[5e000] via P2P/IPC
node209:729900:730336 [2] NCCL INFO Channel 01 : 2[5f000] -> 3[62000] via P2P/IPC
node209:729901:730335 [3] NCCL INFO Channel 01 : 3[62000] -> 0[5b000] via P2P/IPC
node209:729899:730334 [1] NCCL INFO Channel 00 : 1[5e000] -> 2[5f000] via P2P/IPC
node209:729899:730334 [1] NCCL INFO Channel 01 : 1[5e000] -> 2[5f000] via P2P/IPC
node209:729898:730330 [0] NCCL INFO Connected all rings
node209:729901:730335 [3] NCCL INFO Connected all rings
node209:729899:730334 [1] NCCL INFO Connected all rings
node209:729901:730335 [3] NCCL INFO Channel 00 : 3[62000] -> 2[5f000] via P2P/IPC
node209:729900:730336 [2] NCCL INFO Connected all rings
node209:729901:730335 [3] NCCL INFO Channel 01 : 3[62000] -> 2[5f000] via P2P/IPC
node209:729899:730334 [1] NCCL INFO Channel 00 : 1[5e000] -> 0[5b000] via P2P/IPC
node209:729899:730334 [1] NCCL INFO Channel 01 : 1[5e000] -> 0[5b000] via P2P/IPC
node209:729900:730336 [2] NCCL INFO Channel 00 : 2[5f000] -> 1[5e000] via P2P/IPC
node209:729900:730336 [2] NCCL INFO Channel 01 : 2[5f000] -> 1[5e000] via P2P/IPC
node209:729898:730330 [0] NCCL INFO Connected all trees
node209:729898:730330 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
node209:729898:730330 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node209:729901:730335 [3] NCCL INFO Connected all trees
node209:729901:730335 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
node209:729901:730335 [3] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node209:729899:730334 [1] NCCL INFO Connected all trees
node209:729899:730334 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
node209:729899:730334 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node209:729900:730336 [2] NCCL INFO Connected all trees
node209:729900:730336 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
node209:729900:730336 [2] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node209:729899:730334 [1] NCCL INFO comm 0x7f4064003010 rank 1 nranks 4 cudaDev 1 busId 5e000 - Init COMPLETE
node209:729901:730335 [3] NCCL INFO comm 0x7fb86c003010 rank 3 nranks 4 cudaDev 3 busId 62000 - Init COMPLETE
node209:729900:730336 [2] NCCL INFO comm 0x7fca38003010 rank 2 nranks 4 cudaDev 2 busId 5f000 - Init COMPLETE
node209:729898:730330 [0] NCCL INFO comm 0x7f535c003010 rank 0 nranks 4 cudaDev 0 busId 5b000 - Init COMPLETE
node209:729898:729898 [0] NCCL INFO Launch mode Parallel
05/17 17:05:51 - mmengine - INFO - ------------------------------
05/17 17:05:51 - mmengine - INFO - The length of training dataset: 1938
05/17 17:05:51 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 5051   |
| truck                | 525    |
| trailer              | 60     |
| bus                  | 369    |
| construction_vehicle | 196    |
| bicycle              | 191    |
| motorcycle           | 212    |
| pedestrian           | 3657   |
| traffic_cone         | 1339   |
| barrier              | 2323   |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
05/17 17:05:51 - mmengine - INFO - ------------------------------
05/17 17:05:51 - mmengine - INFO - The length of training dataset: 1938
05/17 17:05:51 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 5051   |
| truck                | 525    |
| trailer              | 60     |
| bus                  | 369    |
| construction_vehicle | 196    |
| bicycle              | 191    |
| motorcycle           | 212    |
| pedestrian           | 3657   |
| traffic_cone         | 1339   |
| barrier              | 2323   |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
05/17 17:05:51 - mmengine - INFO - ------------------------------
05/17 17:05:51 - mmengine - INFO - The length of training dataset: 1938
05/17 17:05:51 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 5051   |
| truck                | 525    |
| trailer              | 60     |
| bus                  | 369    |
| construction_vehicle | 196    |
| bicycle              | 191    |
| motorcycle           | 212    |
| pedestrian           | 3657   |
| traffic_cone         | 1339   |
| barrier              | 2323   |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
05/17 17:05:51 - mmengine - INFO - ------------------------------
05/17 17:05:51 - mmengine - INFO - The length of training dataset: 1938
05/17 17:05:51 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 5051   |
| truck                | 525    |
| trailer              | 60     |
| bus                  | 369    |
| construction_vehicle | 196    |
| bicycle              | 191    |
| motorcycle           | 212    |
| pedestrian           | 3657   |
| traffic_cone         | 1339   |
| barrier              | 2323   |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
05/17 17:05:51 - mmengine - INFO - ------------------------------
05/17 17:05:51 - mmengine - INFO - The length of training dataset: 486
05/17 17:05:51 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 2568   |
| truck                | 124    |
| trailer              | 0      |
| bus                  | 41     |
| construction_vehicle | 0      |
| bicycle              | 52     |
| motorcycle           | 259    |
| pedestrian           | 1358   |
| traffic_cone         | 39     |
| barrier              | 0      |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
05/17 17:05:51 - mmengine - INFO - ------------------------------
05/17 17:05:51 - mmengine - INFO - The length of training dataset: 486
05/17 17:05:51 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 2568   |
| truck                | 124    |
| trailer              | 0      |
| bus                  | 41     |
| construction_vehicle | 0      |
| bicycle              | 52     |
| motorcycle           | 259    |
| pedestrian           | 1358   |
| traffic_cone         | 39     |
| barrier              | 0      |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
05/17 17:05:51 - mmengine - INFO - ------------------------------
05/17 17:05:51 - mmengine - INFO - The length of training dataset: 486
05/17 17:05:51 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 2568   |
| truck                | 124    |
| trailer              | 0      |
| bus                  | 41     |
| construction_vehicle | 0      |
| bicycle              | 52     |
| motorcycle           | 259    |
| pedestrian           | 1358   |
| traffic_cone         | 39     |
| barrier              | 0      |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
05/17 17:05:51 - mmengine - INFO - ------------------------------
05/17 17:05:51 - mmengine - INFO - The length of training dataset: 486
05/17 17:05:51 - mmengine - INFO - The number of instances per category in the dataset:
+----------------------+--------+
| category             | number |
+----------------------+--------+
| car                  | 2568   |
| truck                | 124    |
| trailer              | 0      |
| bus                  | 41     |
| construction_vehicle | 0      |
| bicycle              | 52     |
| motorcycle           | 259    |
| pedestrian           | 1358   |
| traffic_cone         | 39     |
| barrier              | 0      |
+----------------------+--------+
INFO:root:Using label names: ['car'], label ids: [0]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
INFO:root:Project config
INFO:root:model:
  base_learning_rate: 4.5e-06
  target: src.models.autoencoder.PoseAutoencoder
  params:
    monitor: val/rec_loss
    embed_dim: 16
    euler_convention: XYZ
    activation: relu
    dropout_prob_init: 1.0
    dropout_prob_final: 0.7
    pose_conditioned_generation_steps: 7000
    dropout_warmup_steps: 5000
    add_noise_to_z_obj: true
    train_on_yaw: true
    lossconfig:
      target: src.modules.losses.PoseLoss
      params:
        encoder_pretrain_steps: 750
        disc_start: 10000
        kl_weight_obj: 1.0
        kl_weight_bbox: 1.0e-06
        disc_weight: 0.5
        pose_weight: 80000
        fill_factor_weight: 500000
        class_weight: 1000000
        bbox_weight: 200000
        pose_loss_fn: l1
        mask_weight: 0
        mask_loss_fn: l2
        disc_in_channels: 3
        num_classes: 1
        dataset_stats_path: dataset_stats/NuScenesTrain-old.pkl
        train_on_yaw: true
    pose_decoder_config:
      target: src.modules.autoencodermodules.pose_decoder.PoseDecoderSpatialVAE
      params:
        num_classes: 1
        num_channels: 16
        'n': 16
        m: 16
        hidden_dim: 500
        num_layers: 2
        activation: tanh
        resid: false
    pose_encoder_config:
      target: src.modules.autoencodermodules.pose_encoder.PoseEncoderSpatialVAE
      params:
        num_classes: 1
        num_channels: 16
        'n': 16
        m: 16
        hidden_dim: 500
        num_layers: 2
        activation: swish
    ddconfig:
      double_z: true
      z_channels: 16
      resolution: 64
      in_channels: 3
      out_ch: 3
      ch: 128
      ch_mult:
      - 1
      - 1
      - 2
      - 2
      - 4
      num_res_blocks: 2
      attn_resolutions:
      - 16
      dropout: 0.0
data:
  data_root: data/nuscenes
  target: src.data.preprocessing.data_modules.DataModuleFromConfig
  params:
    batch_size: 4
    num_workers: 0
    wrap: true
    persistent_workers: false
    train:
      target: src.data.datasets.nuscenes.NuScenesTrainMini
      params:
        data_root: data/nuscenes
        pipeline: []
        box_type_3d: Camera
        load_type: frame_based
        modality:
          use_camera: true
          use_lidar: false
        filter_empty_gt: false
        test_mode: false
        with_velocity: false
        use_valid_flag: false
        label_names:
        - car
        patch_height: 256
        patch_aspect_ratio: 1.0
        perturb_center: true
        perturb_scale: true
    validation:
      target: src.data.datasets.nuscenes.NuScenesValidationMini
      params:
        data_root: data/nuscenes
        pipeline: []
        box_type_3d: Camera
        load_type: frame_based
        modality:
          use_camera: true
          use_lidar: false
        filter_empty_gt: false
        test_mode: false
        with_velocity: false
        use_valid_flag: false
        label_names:
        - car
        patch_height: 256
        patch_aspect_ratio: 1.0
        perturb_center: false

INFO:root:Lightning config
INFO:root:callbacks:
  image_logger:
    target: src.util.callbacks.ImageLogger
    params:
      batch_frequency: 1000
      max_images: 8
      increase_log_steps: true
      disable_local_logging: false
  progress_bar:
    target: src.util.callbacks.TQDMProgressBar
    params:
      refresh_rate: 1
      process_position: 0
  device_stats_monitor:
    target: src.util.callbacks.DeviceStatsMonitor
trainer:
  accumulate_grad_batches: 1
  accelerator: gpu
  max_epochs: 1000
  devices: '4'


  | Name            | Type                  | Params
----------------------------------------------------------
0 | encoder         | FeatEncoder           | 26.7 M
1 | decoder         | FeatDecoder           | 39.0 M
2 | loss            | PoseLoss              | 17.5 M
3 | quant_conv_obj  | Conv2d                | 1.1 K 
4 | quant_conv_pose | Conv2d                | 528   
5 | post_quant_conv | Conv2d                | 272   
6 | pose_decoder    | PoseDecoderSpatialVAE | 2.3 M 
7 | pose_encoder    | PoseEncoderSpatialVAE | 3.1 M 
----------------------------------------------------------
73.8 M    Trainable params
14.7 M    Non-trainable params
88.6 M    Total params
354.204   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 104 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/data/datasets/nuscenes.py:470: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  patch_size_original = torch.tensor(patch_size_original, dtype=torch.float32, requires_grad=False)
/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/data/datasets/nuscenes.py:470: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  patch_size_original = torch.tensor(patch_size_original, dtype=torch.float32, requires_grad=False)
/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/data/datasets/nuscenes.py:470: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  patch_size_original = torch.tensor(patch_size_original, dtype=torch.float32, requires_grad=False)
/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/data/datasets/nuscenes.py:470: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  patch_size_original = torch.tensor(patch_size_original, dtype=torch.float32, requires_grad=False)
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:84: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 4. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/rec_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/total_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/logvar', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/kl_loss_obj', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/nll_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/weighted_nll_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/d_weight', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/disc_factor', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/g_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/pose_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/weighted_pose_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/mask_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/weighted_mask_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/class_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/weighted_class_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/bbox_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/weighted_bbox_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/t1_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/t2_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/t3_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/v3_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/kl_loss_bbox', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/weighted_kl_loss_bbox', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/weighted_kl_loss_obj', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/fill_factor_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/weighted_fill_factor_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/disc_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/logits_real', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val/logits_fake', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
  warning_cache.warn(
/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 104 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/models/autoencoder.py:424: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  log["reconstructions_rgb"] = torch.tensor(xrec_rgb)
/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/models/autoencoder.py:425: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  log["perturbed_pose_reconstruction_rgb"] = torch.tensor(xrec_perturbed_pose_rgb)
/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/models/autoencoder.py:427: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  log["inputs_rgb"] = torch.tensor(x_rgb)
ERROR:root:SetupCallback.on_exception() takes 3 positional arguments but 4 were given
Traceback (most recent call last):
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 38, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 650, in _fit_impl
    self._run(model, ckpt_path=self.ckpt_path)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1103, in _run
    results = self._run_stage()
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1182, in _run_stage
    self._run_train()
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1205, in _run_train
    self.fit_loop.run()
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
    self.advance(*args, **kwargs)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 267, in advance
    self._outputs = self.epoch_loop.run(self._data_fetcher)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
    self.advance(*args, **kwargs)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 229, in advance
    self.trainer._call_callback_hooks("on_train_batch_end", batch_end_outputs, batch, batch_idx)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1385, in _call_callback_hooks
    fn(self, self.lightning_module, *args, **kwargs)
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/util/callbacks.py", line 210, in on_train_batch_end
    self.log_img(pl_module, batch, batch_idx, split="train")
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/util/callbacks.py", line 175, in log_img
    images = pl_module.log_images(batch, split=split, **self.log_images_kwargs)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/models/autoencoder.py", line 411, in log_images
    xrec_perturbed_pose = self._perturbed_pose_forward(posterior_obj, poserec, batch) #torch.Size([4, 3, 256, 256])
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/models/autoencoder.py", line 388, in _perturbed_pose_forward
    enc_pose_perturbed = self._encode_pose(dec_pose_perturbed) # torch.Size([4, 16, 16, 16])
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/models/autoencoder.py", line 173, in _encode_pose
    flattened_encoded_pose_feat_map = self.pose_encoder(x) # torch.Size([4, 4096]) = 4, 16*16*16
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/modules/autoencodermodules/pose_encoder.py", line 120, in forward
    h_x = self.coord_linear(x) # h_x torch.Size([4, 1024]) = b, 16 * 16 * 4
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:2 and cuda:0! (when checking argument for argument mat1 in method wrapper_addmm)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/train.py", line 484, in main
    trainer.fit(model, data)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 608, in fit
    call._call_and_handle_interrupt(
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 60, in _call_and_handle_interrupt
    trainer._call_callback_hooks("on_exception", exception)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1385, in _call_callback_hooks
    fn(self, self.lightning_module, *args, **kwargs)
TypeError: SetupCallback.on_exception() takes 3 positional arguments but 4 were given
ERROR:root:SetupCallback.on_exception() takes 3 positional arguments but 4 were given
Traceback (most recent call last):
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 38, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 650, in _fit_impl
    self._run(model, ckpt_path=self.ckpt_path)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1103, in _run
    results = self._run_stage()
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1182, in _run_stage
    self._run_train()
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1205, in _run_train
    self.fit_loop.run()
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
    self.advance(*args, **kwargs)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 267, in advance
    self._outputs = self.epoch_loop.run(self._data_fetcher)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
    self.advance(*args, **kwargs)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 229, in advance
    self.trainer._call_callback_hooks("on_train_batch_end", batch_end_outputs, batch, batch_idx)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1385, in _call_callback_hooks
    fn(self, self.lightning_module, *args, **kwargs)
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/util/callbacks.py", line 210, in on_train_batch_end
    self.log_img(pl_module, batch, batch_idx, split="train")
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/util/callbacks.py", line 175, in log_img
    images = pl_module.log_images(batch, split=split, **self.log_images_kwargs)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/models/autoencoder.py", line 411, in log_images
    xrec_perturbed_pose = self._perturbed_pose_forward(posterior_obj, poserec, batch) #torch.Size([4, 3, 256, 256])
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/models/autoencoder.py", line 388, in _perturbed_pose_forward
    enc_pose_perturbed = self._encode_pose(dec_pose_perturbed) # torch.Size([4, 16, 16, 16])
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/models/autoencoder.py", line 173, in _encode_pose
    flattened_encoded_pose_feat_map = self.pose_encoder(x) # torch.Size([4, 4096]) = 4, 16*16*16
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/modules/autoencodermodules/pose_encoder.py", line 120, in forward
    h_x = self.coord_linear(x) # h_x torch.Size([4, 1024]) = b, 16 * 16 * 4
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:0! (when checking argument for argument mat1 in method wrapper_addmm)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/train.py", line 484, in main
    trainer.fit(model, data)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 608, in fit
    call._call_and_handle_interrupt(
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 60, in _call_and_handle_interrupt
    trainer._call_callback_hooks("on_exception", exception)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1385, in _call_callback_hooks
    fn(self, self.lightning_module, *args, **kwargs)
TypeError: SetupCallback.on_exception() takes 3 positional arguments but 4 were given
Traceback (most recent call last):
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 38, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 650, in _fit_impl
ERROR:root:SetupCallback.on_exception() takes 3 positional arguments but 4 were given
Traceback (most recent call last):
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 38, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 650, in _fit_impl
    self._run(model, ckpt_path=self.ckpt_path)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1103, in _run
    results = self._run_stage()
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1182, in _run_stage
    self._run_train()
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1205, in _run_train
    self.fit_loop.run()
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
    self.advance(*args, **kwargs)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 267, in advance
    self._outputs = self.epoch_loop.run(self._data_fetcher)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
    self.advance(*args, **kwargs)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 229, in advance
    self.trainer._call_callback_hooks("on_train_batch_end", batch_end_outputs, batch, batch_idx)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1385, in _call_callback_hooks
    fn(self, self.lightning_module, *args, **kwargs)
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/util/callbacks.py", line 210, in on_train_batch_end
    self.log_img(pl_module, batch, batch_idx, split="train")
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/util/callbacks.py", line 175, in log_img
    images = pl_module.log_images(batch, split=split, **self.log_images_kwargs)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/models/autoencoder.py", line 411, in log_images
    xrec_perturbed_pose = self._perturbed_pose_forward(posterior_obj, poserec, batch) #torch.Size([4, 3, 256, 256])
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/models/autoencoder.py", line 388, in _perturbed_pose_forward
    enc_pose_perturbed = self._encode_pose(dec_pose_perturbed) # torch.Size([4, 16, 16, 16])
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/models/autoencoder.py", line 173, in _encode_pose
    flattened_encoded_pose_feat_map = self.pose_encoder(x) # torch.Size([4, 4096]) = 4, 16*16*16
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/modules/autoencodermodules/pose_encoder.py", line 120, in forward
    h_x = self.coord_linear(x) # h_x torch.Size([4, 1024]) = b, 16 * 16 * 4
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:3 and cuda:0! (when checking argument for argument mat1 in method wrapper_addmm)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/train.py", line 484, in main
    trainer.fit(model, data)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 608, in fit
    call._call_and_handle_interrupt(
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 60, in _call_and_handle_interrupt
    trainer._call_callback_hooks("on_exception", exception)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1385, in _call_callback_hooks
    fn(self, self.lightning_module, *args, **kwargs)
TypeError: SetupCallback.on_exception() takes 3 positional arguments but 4 were given
    self._run(model, ckpt_path=self.ckpt_path)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1103, in _run
Traceback (most recent call last):
    results = self._run_stage()
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1182, in _run_stage
Traceback (most recent call last):
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 38, in _call_and_handle_interrupt
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 38, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
    return trainer_fn(*args, **kwargs)
    self._run_train()
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1205, in _run_train
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 650, in _fit_impl
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 650, in _fit_impl
    self.fit_loop.run()
    self._run(model, ckpt_path=self.ckpt_path)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1103, in _run
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
    self.advance(*args, **kwargs)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 267, in advance
    self._run(model, ckpt_path=self.ckpt_path)
    self._outputs = self.epoch_loop.run(self._data_fetcher)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
    results = self._run_stage()
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1182, in _run_stage
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1103, in _run
    self.advance(*args, **kwargs)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 229, in advance
    self.trainer._call_callback_hooks("on_train_batch_end", batch_end_outputs, batch, batch_idx)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1385, in _call_callback_hooks
    results = self._run_stage()
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1182, in _run_stage
    self._run_train()
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1205, in _run_train
    fn(self, self.lightning_module, *args, **kwargs)
    self._run_train()
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1205, in _run_train
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/util/callbacks.py", line 210, in on_train_batch_end
    self.fit_loop.run()
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
    self.log_img(pl_module, batch, batch_idx, split="train")
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/util/callbacks.py", line 175, in log_img
    images = pl_module.log_images(batch, split=split, **self.log_images_kwargs)
    self.fit_loop.run()
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    self.advance(*args, **kwargs)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 267, in advance
    self.advance(*args, **kwargs)
    return func(*args, **kwargs)
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/models/autoencoder.py", line 411, in log_images
    self._outputs = self.epoch_loop.run(self._data_fetcher)
    xrec_perturbed_pose = self._perturbed_pose_forward(posterior_obj, poserec, batch) #torch.Size([4, 3, 256, 256])
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/models/autoencoder.py", line 388, in _perturbed_pose_forward
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 267, in advance
    enc_pose_perturbed = self._encode_pose(dec_pose_perturbed) # torch.Size([4, 16, 16, 16])
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/models/autoencoder.py", line 173, in _encode_pose
    self.advance(*args, **kwargs)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 229, in advance
    self._outputs = self.epoch_loop.run(self._data_fetcher)
    flattened_encoded_pose_feat_map = self.pose_encoder(x) # torch.Size([4, 4096]) = 4, 16*16*16     
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    self.trainer._call_callback_hooks("on_train_batch_end", batch_end_outputs, batch, batch_idx)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1385, in _call_callback_hooks
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
    return forward_call(*input, **kwargs)
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/modules/autoencodermodules/pose_encoder.py", line 120, in forward
    h_x = self.coord_linear(x) # h_x torch.Size([4, 1024]) = b, 16 * 16 * 4
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    fn(self, self.lightning_module, *args, **kwargs)
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/util/callbacks.py", line 210, in on_train_batch_end
    self.advance(*args, **kwargs)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 229, in advance
    self.trainer._call_callback_hooks("on_train_batch_end", batch_end_outputs, batch, batch_idx)
    return forward_call(*input, **kwargs)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1385, in _call_callback_hooks
    self.log_img(pl_module, batch, batch_idx, split="train")
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/util/callbacks.py", line 175, in log_img
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:2 and cuda:0! (when checking argument for argument mat1 in method wrapper_addmm)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
    fn(self, self.lightning_module, *args, **kwargs)
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/util/callbacks.py", line 210, in on_train_batch_end
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/train.py", line 513, in <module>
    images = pl_module.log_images(batch, split=split, **self.log_images_kwargs)
    main()
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/train.py", line 484, in main
    self.log_img(pl_module, batch, batch_idx, split="train")
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/util/callbacks.py", line 175, in log_img
    trainer.fit(model, data)
    return func(*args, **kwargs)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 608, in fit
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/models/autoencoder.py", line 411, in log_images
    images = pl_module.log_images(batch, split=split, **self.log_images_kwargs)
    call._call_and_handle_interrupt(
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 60, in _call_and_handle_interrupt
    trainer._call_callback_hooks("on_exception", exception)
    xrec_perturbed_pose = self._perturbed_pose_forward(posterior_obj, poserec, batch) #torch.Size([4, 3, 256, 256])
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1385, in _call_callback_hooks
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/models/autoencoder.py", line 388, in _perturbed_pose_forward
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    enc_pose_perturbed = self._encode_pose(dec_pose_perturbed) # torch.Size([4, 16, 16, 16])
    return func(*args, **kwargs)
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/models/autoencoder.py", line 411, in log_images
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/models/autoencoder.py", line 173, in _encode_pose
    fn(self, self.lightning_module, *args, **kwargs)
TypeError: SetupCallback.on_exception() takes 3 positional arguments but 4 were given
    xrec_perturbed_pose = self._perturbed_pose_forward(posterior_obj, poserec, batch) #torch.Size([4, 3, 256, 256])
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/models/autoencoder.py", line 388, in _perturbed_pose_forward
    flattened_encoded_pose_feat_map = self.pose_encoder(x) # torch.Size([4, 4096]) = 4, 16*16*16     
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    enc_pose_perturbed = self._encode_pose(dec_pose_perturbed) # torch.Size([4, 16, 16, 16])
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/models/autoencoder.py", line 173, in _encode_pose
    return forward_call(*input, **kwargs)
    flattened_encoded_pose_feat_map = self.pose_encoder(x) # torch.Size([4, 4096]) = 4, 16*16*16     
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/modules/autoencodermodules/pose_encoder.py", line 120, in forward
    return forward_call(*input, **kwargs)
    h_x = self.coord_linear(x) # h_x torch.Size([4, 1024]) = b, 16 * 16 * 4
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/src/modules/autoencodermodules/pose_encoder.py", line 120, in forward
    return forward_call(*input, **kwargs)
    h_x = self.coord_linear(x) # h_x torch.Size([4, 1024]) = b, 16 * 16 * 4
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return forward_call(*input, **kwargs)
    return F.linear(input, self.weight, self.bias)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:0! (when checking argument for argument mat1 in method wrapper_addmm)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 114, in forward

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/train.py", line 513, in <module>
    return F.linear(input, self.weight, self.bias)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:3 and cuda:0! (when checking argument for argument mat1 in method wrapper_addmm)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
    main()
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/train.py", line 513, in <module>
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/train.py", line 484, in main
    main()
    trainer.fit(model, data)
  File "/n/fs/pci-sharedt/jo5483/workspace/generative-detection/train.py", line 484, in main
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 608, in fit
    trainer.fit(model, data)
    call._call_and_handle_interrupt(
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 608, in fit
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 60, in _call_and_handle_interrupt
    call._call_and_handle_interrupt(
    trainer._call_callback_hooks("on_exception", exception)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1385, in _call_callback_hooks
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 60, in _call_and_handle_interrupt
    fn(self, self.lightning_module, *args, **kwargs)
    trainer._call_callback_hooks("on_exception", exception)
  File "/n/fs/pci-sharedt/jo5483/miniconda3/envs/test_mmdet3d/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1385, in _call_callback_hooks
TypeError: SetupCallback.on_exception() takes 3 positional arguments but 4 were given
    fn(self, self.lightning_module, *args, **kwargs)
TypeError: SetupCallback.on_exception() takes 3 positional arguments but 4 were given
srun: error: node209: tasks 1-2: Exited with exit code 1
srun: error: node209: task 3: Exited with exit code 1
srun: Job step aborted: Waiting up to 92 seconds for job step to finish.
slurmstepd: error: *** JOB 20823715 ON node209 CANCELLED AT 2024-05-17T17:26:13 ***
slurmstepd: error: *** STEP 20823715.0 ON node209 CANCELLED AT 2024-05-17T17:26:13 ***
